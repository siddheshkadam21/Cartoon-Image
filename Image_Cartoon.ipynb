{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps:-\n",
    "    1.Apply a bilateral filter to reduce the color palette of the image.\n",
    "    2.Convert original color image into grayscale image.\n",
    "    3.Apply median blur to reduce image noise in the resultant grayscale image.\n",
    "    4.Create an edge mask from the grayscale image using adaptive thresholding.\n",
    "    5.Combine the color image from step 1 eith edge mask from step 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DownSampling and Giving bilateral filtering steps\n",
    "- Downsampling is the reduction in spatial resolution while keeping the same two-dimensional (2D) representation.\n",
    "- A bilateral filter is a non-linear, edge-preserving, and noise-reducing smoothing filter for images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_down=2   # number of downsampling steps\n",
    "num_bilateral=2  # number bilateral filtering steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb=cv2.imread(\"cool_buddy.jpg\")\n",
    "#elon-musk-spacex-2\n",
    "#elon_musk_reuters_1610084738222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1079, 1080, 3)\n"
     ]
    }
   ],
   "source": [
    "img_rgb = np.array(img_rgb, dtype=np.uint8)\n",
    "print(img_rgb.shape)# print the dimension of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing original image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing so as to get the optimal result after un sampling is done\n",
    "img_rgb=cv2.resize(img_rgb,(400,400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample the image ,apply the bilateral filter ,mentioned the amount time \n",
    "- Gaussian pyramid involves applying repeated Gaussian blurring and downsampling an image until some stopping criteria are met. \n",
    "- For instance, one of the stopping criteria can be the minimum image size. \n",
    "- cv2.pyrDown() function decreases the size to half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample image using gaussian pyramid\n",
    "img_color=img_rgb\n",
    "for i in range(num_bilateral):\n",
    "    img_color=cv2.pyrDown(img_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reptedly applying small bilateral filter.\n",
    "- A bilateral filter is used for smoothening images and reducing noise, while preserving edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetedly applying small bilateral filter instead of applying one large filter\n",
    "for i in range(num_bilateral):\n",
    "    img_color=cv2.bilateralFilter(img_color,d=9,sigmaColor=9,sigmaSpace=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unsample, convert the image to grayscale, apply median blur and then thresholding\n",
    "- cv2.pyrUp() function increases the size to double of its original size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsample the image to original size\n",
    "for i in range (num_down):\n",
    "    img_color=cv2.pyrUp(img_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cv2.cvtColor() method is used to convert an image from one color space to another. \n",
    "- cv2.medianBlur() computes the median of all the pixels under the kernel window and the central pixel is replaced with this median value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray=cv2.cvtColor(img_rgb,cv2.COLOR_RGB2GRAY)\n",
    "img_blur=cv2.medianBlur(img_gray,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When image has different lighting conditions in different areas we use cv2.adaptiveThreshold\n",
    "    - cv2.ADAPTIVE_THRESH_MEAN_C threshold value is the mean of neighbourhood area.\n",
    "    - cv2.THRESH_BINARY If pixel intensity is greater than the set threshold, value set to 255, else set to 0 (black).\n",
    "    - blockSize It decides the size of neighbourhood area.\n",
    "    - C It is just a constant which is subtracted from the mean or weighted mean calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_edge=cv2.adaptiveThreshold(img_blur,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,blockSize=5,C=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert  Gray image into RGB image \n",
    "- cv2.cvtColor for colour conversion\n",
    "- cv2.COLOR_GRAY2RGB GRAY image into RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert black to color ,bit-AND with color image\n",
    "img_edge=cv2.cvtColor(img_edge,cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking data type and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "(400, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "#checking data type and shape\n",
    "print(img_edge.dtype)\n",
    "print(img_edge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "(400, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "#checking data type and shape\n",
    "print(img_color.dtype)\n",
    "print(img_color.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing both the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 400, 3)\n",
      "(400, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "#making same size of both images\n",
    "img_color=cv2.resize(img_color,(400,400))\n",
    "print(img_color.shape)\n",
    "img_edge=cv2.resize(img_edge,(400,400))\n",
    "print(img_edge.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bitwise operations are used in image manipulation and used for extracting essential parts in the image. \n",
    "- cv2.bitwise_and Bit-wise conjunction of input array elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "img_cartoon=cv2.bitwise_and(img_color, img_edge)\n",
    "print(img_cartoon.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real and Cartoon image\n",
    "- np.hstack() function is used to stack the sequence of input arrays horizontally \n",
    "- cv2.imshow() method is used to display an image in a window.\n",
    "- cv2.waitKey(0) will display the window infinitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack=np.hstack([img_rgb,img_cartoon])\n",
    "cv2.imshow(\"Original Image and Cartoon Image \",stack)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
